# Agent Runner (LLM + Tool ì—°ê²°)
from app.agent.llm import llm
from app.agent.tool_dispatcher import dispatch_tool
from app.agent.schemas import TOOLS_SCHEMA
from app.agent.conversation_manager import ConversationManager
import json

SESSION_MESSAGES: dict[str, list] = {}

async def run_agent(user_message: str, userid: str):

    if userid not in SESSION_MESSAGES:
        SESSION_MESSAGES[userid] = [
            {"role": "system", "content": "You are a crypto trading assistant."}
        ]

    messages = SESSION_MESSAGES[userid]

    messages.append({"role": "user", "content": user_message})

    response = llm.chat(
        messages=messages,
        tools=TOOLS_SCHEMA,
        tool_choice="auto"
    )

    msg = response.get("message", {})

    if isinstance(msg, dict) and "tool_call" in msg:
        tool_call = msg["tool_call"]

        try:
            tool_result = dispatch_tool(
                tool_call=tool_call,
                userid=userid
            )
        except Exception as e:
            print("ğŸ”¥ TOOL ERROR:", e)
            raise

        final_response = llm.chat(
            messages=[
                {"role": "system", "content": "You are a crypto trading assistant."},
                {"role": "assistant", "content": json.dumps(tool_result, ensure_ascii=False)},
                {"role": "user", "content": "ìœ„ ê²°ê³¼ë¥¼ ì‚¬ìš©ìì—ê²Œ ìì—°ìŠ¤ëŸ½ê²Œ ì„¤ëª…í•´ì¤˜."}
            ]
        )

        answer = final_response["message"]["content"]

        messages.append({"role": "assistant", "content": answer})

        return {"answer": answer, "tool": tool_call["name"]}

    # ì¼ë°˜ ë‹µë³€
    content = msg.get("content", "")
    messages.append({"role": "assistant", "content": content})

    return {"answer": content, "tool": None}


# agent_prompt = """
# You are a professional crypto market research AI agent.

# You provide INFORMATION ONLY.
# You must NEVER give investment advice, predictions, or trading recommendations.

# You have access to the following tools and MUST use them according to the rules.

# NEWS TOOL:
# - get_crypto_news â†’ use when question involves events, reasons, incidents, regulations, hacks, policy, ETF, investigations, outages.

# MARKET TOOLS:
# - Price â†’ get_price
# - 24H statistics â†’ get_24h_stats
# - Comparison â†’ compare_symbols
# - Movers â†’ get_top_movers
# - Market ranking â†’ get_market_cap
# - Trending coins â†’ get_trending_coins
# - Market summary â†’ get_market_snapshot

# ECONOMY TERM TOOL:
# - search_crypto_term â†’ use when question asks about financial concepts, economic terms, policies, indicators, theories, macroeconomic definitions.

# PORTFOLIO TOOLS:
# - get_user_profile
# - get_latest_strategy
# - get_strategy_by_date

# Multi-turn memory
# - Always consider previous conversation context
# - Do NOT change topic abruptly unless the user does

# ## OUTPUT RULES
# - Respond in Korean only
# - Never give buy/sell advice
# - Never expose JSON or tool output
# - Keep the tone professional
# - DO NOT answer from memory
# - DO NOT generate a natural language answer first
# - Must use tools 
# """
# # ë©€í‹°í„´
# SESSION_STORE: dict[str, ConversationManager] = {}


# async def run_agent(user_message: str, userid: str):
#     """
#     Stateful Agent Runner
#     - userid ê¸°ì¤€ ConversationManager ìœ ì§€ (ë©€í‹°í„´)
#     - LLMì´ tool íŒë‹¨
#     - tool ë¯¸ì‚¬ìš© ì‹œ ì„œë²„ê°€ ì¬ìš”ì²­ (ê°•ì œ)
#     """

#     # 1ï¸âƒ£ ìœ ì €ë³„ ConversationManager ìƒì„±
#     if userid not in SESSION_STORE:
#         SESSION_STORE[userid] = ConversationManager(
#             llm=llm,
#             system_prompt=agent_prompt
#         )

#     cm = SESSION_STORE[userid]

#     # 2ï¸âƒ£ 1ì°¨ LLM í˜¸ì¶œ (ë©€í‹°í„´ íˆìŠ¤í† ë¦¬ í¬í•¨)
#     result = cm.chat(
#         user_message=user_message,
#         tools=TOOLS_SCHEMA
#     )

#     # 3ï¸âƒ£ Tool í˜¸ì¶œì´ ë‚˜ì˜¨ ê²½ìš°
#     if result["type"] == "tool":
#         tool_call = result["tool_call"]

#         # ğŸ”§ ì‹¤ì œ Tool ì‹¤í–‰
#         tool_result = dispatch_tool(
#             tool_call=tool_call,
#             userid=userid
#         )

#         # 4ï¸âƒ£ Tool ê²°ê³¼ â†’ ìì—°ì–´ ì„¤ëª… (LLMì´ ë‹´ë‹¹)
#         final_answer = cm.respond_with_tool_result(
#             tool_result=tool_result
#         )

#         return {
#             "answer": final_answer,
#             "tool_used": tool_call["name"]
#         }

#     # 4ï¸âƒ£ â— Toolì„ ì•ˆ ì¼ë‹¤ë©´ â†’ ì„œë²„ì—ì„œ ê°•ì œ ì¬ìš”ì²­
#     retry = cm.force_tool_call(
#         original_question=user_message,
#         tools=TOOLS_SCHEMA
#     )

#     if retry and retry["type"] == "tool":
#         tool_call = retry["tool_call"]

#         tool_result = dispatch_tool(
#             tool_call=tool_call,
#             userid=userid
#         )

#         final_answer = cm.respond_with_tool_result(
#             tool_result=tool_result
#         )

#         return {
#             "answer": final_answer,
#             "tool_used": tool_call["name"]
#         }

#     # 5ï¸âƒ£ ì§„ì§œ ì˜ˆì™¸ ìƒí™© (ì •ë³´ ì œê³µ ë¶ˆê°€)
#     return {
#         "answer": result["content"],
#         "tool_used": None
# }
# async def run_agent(user_message: str, userid: str):

    
#     messages = [
#         {
#             "role": "system",
#             "content": agent_prompt
#         },
#         {
#             "role": "user",
#             "content": user_message
#         }
#     ]

#     # 1) LLM í˜¸ì¶œ
#     response = llm.chat(
#         messages=messages,
#         tools=TOOLS_SCHEMA,
#         tool_choice="auto"
#     )

#     msg = response["message"]

#     # 2) Tool callì´ ìˆìœ¼ë©´ ì‹¤í–‰
#     if "tool_call" in msg:
#         tool_call = msg["tool_call"]

#         tool_result = dispatch_tool(
#             tool_call=tool_call,
#             userid=userid
#         )

#         # 3) Tool ê²°ê³¼ë¥¼ ë‹¤ì‹œ LLMì— ë³´ë‚´ì„œ ìµœì¢… ë‹µë³€ ìƒì„±
#         followup_messages = messages + [
#             {
#                 "role": "system", 
#                 "content": agent_prompt
#             },
#             {
#                 "role": "assistant",
#                 "content": f"ë„êµ¬ ì‹¤í–‰ ê²°ê³¼ì…ë‹ˆë‹¤:\n{json.dumps(tool_result, ensure_ascii=False)}"
#             },
#             {
#                 "role": "user",
#                 "content": "ìœ„ ê²°ê³¼ë¥¼ ì‚¬ìš©ìì—ê²Œ ìì—°ìŠ¤ëŸ½ê²Œ ì„¤ëª…í•´ì¤˜."
#             }
#         ]

#         final_response = llm.chat(
#             messages=followup_messages
#         )

#         return {
#             "answer": final_response["message"]["content"],
#             "tool": tool_call["name"]
#         }

#     # 4ï¸âƒ£ Tool ì•ˆ ì“´ ì¼ë°˜ ë‹µë³€
#     return {
#         "answer": msg["content"],
#         "tool": None
#         }